{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9324e79-9d17-4e62-875d-04891121c84b",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "In this notebook we simulate using boax for a hyperparemter tuning problem of a SVM.\n",
    "\n",
    "We will begin by defining the latent objective function we want to maximize and its bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07defcc9-2137-421f-a0f4-cb56814310d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "# Double precision is highly recommended.\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "from jax import lax\n",
    "from jax import nn\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax import value_and_grad\n",
    "\n",
    "import optax\n",
    "\n",
    "from boax.core import distributions, samplers\n",
    "from boax.prediction import kernels, likelihoods, means, models\n",
    "from boax.optimization import acquisitions, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7603465-52c0-4fb0-9d62-c5c3196fea60",
   "metadata": {},
   "source": [
    "We use a two-dimensional synthetic objective funtion simulating the accuracy of a SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c78cd9-ecd4-4952-9286-7eb0701ab6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = jnp.array([[0.0, 2.0]] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa140997-c875-4122-9c23-e030409243bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    return (\n",
    "        jnp.sin(5 * x[..., 0] / 2 - 2.5) * jnp.cos(2.5 - 5 * x[..., 1])\n",
    "        + (5 * x[..., 1] / 2 + 0.5) ** 2 / 10\n",
    "    ) / 5 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e95d8b6-ece4-42bd-acaf-c5e723a07e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key, sampler_key, optimization_key = random.split(random.key(0), 3)\n",
    "x_train = random.uniform(data_key, minval=bounds[:, 0], maxval=bounds[:, 1], shape=(10, 2))\n",
    "y_train = objective(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e248c703-21ef-48cc-84bf-41677ab4bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'mean': jnp.zeros(()),\n",
    "    'length_scale': jnp.zeros((2,)),\n",
    "    'amplitude': jnp.zeros(()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22e83f7-b49c-42cf-9bad-798c6d65d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optax.adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf40579f-c274-4a35-ab14-204c9f284b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    def model(mean, length_scale, amplitude):\n",
    "        return models.predictive(\n",
    "            models.gaussian_process(\n",
    "                means.constant(mean),\n",
    "                kernels.scaled(\n",
    "                    kernels.matern_five_halves(nn.softplus(length_scale)),\n",
    "                    nn.softplus(amplitude),\n",
    "                ),\n",
    "            ),\n",
    "            likelihoods.gaussian(1e-4)\n",
    "        )\n",
    "        \n",
    "    def target_log_prob(params):\n",
    "        mvn = model(**params)(x_train)\n",
    "        return -jnp.sum(distributions.multivariate_normal.logpdf(mvn, y_train))\n",
    "\n",
    "    def train_step(state, iteration):\n",
    "        loss, grads = value_and_grad(target_log_prob)(state[0])\n",
    "        updates, opt_state = adam.update(grads, state[1])\n",
    "        params = optax.apply_updates(state[0], updates)\n",
    "        \n",
    "        return (params, opt_state), loss\n",
    "    \n",
    "    return lax.scan(\n",
    "        jit(train_step),\n",
    "        (params, adam.init(params)),\n",
    "        jnp.arange(500)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03fb2443-463f-46b2-8743-fa4a71540aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, q, num_samples, raw_samples = 32, 4, 40, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c9367d0-e694-4541-9c8b-dfce3ff389f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_queries = 20\n",
    "num_iterations = num_queries // q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836ca9d4-aaea-4d00-9a9a-36caa8ee0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_samples = jnp.reshape(\n",
    "    samplers.halton_normal()(\n",
    "        random.fold_in(sampler_key, 0),\n",
    "        s * q,\n",
    "    ),\n",
    "    (s, q)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94dd3dd0-836a-4afb-ab0f-ec81759e3d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = jnp.reshape(\n",
    "    samplers.halton_uniform(distributions.uniform.uniform(bounds[:, 0], bounds[:, 1]))(\n",
    "        random.fold_in(sampler_key, 1),\n",
    "        raw_samples * q,\n",
    "    ),\n",
    "    (raw_samples, q, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec20a90c-cc17-487a-a032-7e183233001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_iterations):    \n",
    "    (next_params, _), _ = fit(x_train, y_train)\n",
    "\n",
    "    acqf = optimizers.construct(\n",
    "        models.sampled(\n",
    "            models.predictive(\n",
    "                models.gaussian_process_regression(\n",
    "                    means.constant(next_params['mean']),\n",
    "                    kernels.scaled(\n",
    "                        kernels.matern_five_halves(nn.softplus(next_params['length_scale'])),\n",
    "                        nn.softplus(next_params['amplitude'])\n",
    "                    ),\n",
    "                )(\n",
    "                    x_train,\n",
    "                    y_train,\n",
    "                ),\n",
    "                likelihoods.gaussian(1e-4)\n",
    "            ),\n",
    "            distributions.multivariate_normal.sample,\n",
    "            base_samples,\n",
    "        ),\n",
    "        acquisitions.q_probability_of_improvement(\n",
    "            tau=1.0,\n",
    "            best=jnp.argmax(y_train)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    bfgs = optimizers.bfgs(\n",
    "        acqf,\n",
    "        bounds,\n",
    "        x0,\n",
    "        num_samples,\n",
    "    )\n",
    "\n",
    "    candidates = bfgs.init(random.fold_in(optimization_key, i))\n",
    "    next_candidates, values = bfgs.update(candidates)\n",
    "    \n",
    "    next_x = next_candidates[jnp.argmax(values)]\n",
    "    next_y = objective(next_x)\n",
    "\n",
    "    x_train = jnp.vstack([x_train, next_x])\n",
    "    y_train = jnp.hstack([y_train, next_y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
