{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14b8e7c-79f8-491c-ad6e-7a57c1103425",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this notebook we use boax to demonstrate a single step of a typical bayesion optimization process.\n",
    "\n",
    "We will begin by defining the latent objective function we want to maximize and its bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c736af-ef31-4b7c-bfc1-0483e70ca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "# Double precision is highly recommended.\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "from jax import lax\n",
    "from jax import nn\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax import scipy\n",
    "from jax import value_and_grad\n",
    "\n",
    "import optax\n",
    "\n",
    "from boax.prediction import kernels, means, models\n",
    "from boax.optimization import acquisitions, maximizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4882-c610-4448-8699-545cecb97631",
   "metadata": {},
   "source": [
    "As our latent objective function we chose a sinusoid that we aim to maximize in the interval of [-3, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0aa909-2832-47e2-9427-01cd163b712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = jnp.array([[-3, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5385417b-ebb4-4e75-89aa-0215d21e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "  return jnp.sin(4 * x[..., 0]) + jnp.cos(2 * x[..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00407e4b-1c72-4540-a08a-accd1216d277",
   "metadata": {},
   "source": [
    "To create the observation training data we sample random points from a uniform distribution, evaluate the objective functions at those points, and finish by adding gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6f727-86ed-4f31-aeda-ea380ee228fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key, noise_key, maximizer_key = random.split(random.key(0), 3)\n",
    "x_train = random.uniform(sample_key, minval=bounds[0, 0], maxval=bounds[0, 1], shape=(10, 1))\n",
    "y_train = objective(x_train) + 0.3 * random.normal(noise_key, shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846011-f012-4d34-8529-c74ede9a6adf",
   "metadata": {},
   "source": [
    "## Fitting a Gaussian Process model to the data\n",
    "\n",
    "With the observations in place, we can now focus on constructing a Gaussian Process model and fit it to the data. For this example we choose a simple setup of a constant zero mean function and a scaled RBF kernel. Note that we use the softplus function to constrain some of the models' hyperparameters to be strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d40cc2-de01-4b9a-a9fa-80aebf353afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(amplitude, length_scale, noise):\n",
    "    return models.gaussian_process(\n",
    "        means.zero(),\n",
    "        kernels.scaled(kernels.rbf(nn.softplus(length_scale)), nn.softplus(amplitude)),\n",
    "        nn.softplus(noise),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d664e642-509b-4000-bb46-85605f477133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob(params):\n",
    "    mean, cov = prior(**params)(x_train)\n",
    "    return -scipy.stats.multivariate_normal.logpdf(y_train, mean, cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecb90-c62a-4d25-97eb-fb601691843f",
   "metadata": {},
   "source": [
    "Next we initialise the models' hyperparameters, the optimizer, and fit the model to the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d076f8a7-24cf-4155-80d9-21b796531544",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'amplitude': jnp.zeros(()),\n",
    "  'length_scale': jnp.zeros(()),\n",
    "  'noise': jnp.array(-5.),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ee0023-19ed-4c4b-b35f-49e3b8c3647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89522430-b013-483c-a28d-8b3a5a111e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, iteration):\n",
    "  loss, grads = value_and_grad(target_log_prob)(state[0])\n",
    "  updates, opt_state = optimizer.update(grads, state[1])\n",
    "  params = optax.apply_updates(state[0], updates)\n",
    "\n",
    "  return (params, opt_state), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8b89cb-1769-4d35-9583-7515325b0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(next_params, next_opt_state), history = lax.scan(\n",
    "    jit(train_step),\n",
    "    (params, optimizer.init(params)),\n",
    "    jnp.arange(500)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283a8d8-0076-42e3-abf9-c2a253e5a1a3",
   "metadata": {},
   "source": [
    "## Constructing and optimizing an acquisition function\n",
    "\n",
    "As a final step we use the posterior of our Gaussian Process model to construct the Upper Bound Confidence acquisition function which we maximize using the BFGS optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c468936c-6aea-41c6-a794-e7a885da0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = models.gaussian_process_regression(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    means.zero(),\n",
    "    kernels.scaled(kernels.rbf(nn.softplus(next_params['length_scale'])), nn.softplus(next_params['amplitude'])),\n",
    "    nn.softplus(next_params['noise']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31b1562-5cc6-4a84-9f9e-8ee0f6f0c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "acqf = acquisitions.upper_confidence_bound(surrogate, beta=2.0)\n",
    "maximizer = maximizers.bfgs(bounds, q=1, num_restarts=25, num_raw_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0e6c4c9-dd2e-481c-a446-101ead7c1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = maximizer.init(maximizer_key, acqf)\n",
    "next_candidates, values = maximizer.maximize(candidates, acqf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
