{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14b8e7c-79f8-491c-ad6e-7a57c1103425",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this notebook we use boax to demonstrate a single step of a typical bayesion optimization process.\n",
    "\n",
    "We will begin by defining the latent objective function we want to maximize and its bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c736af-ef31-4b7c-bfc1-0483e70ca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "# Double precision is highly recommended.\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "from jax import lax\n",
    "from jax import nn\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax import value_and_grad\n",
    "\n",
    "import optax\n",
    "\n",
    "from boax.core import distributions\n",
    "from boax.prediction import kernels, likelihoods, means, models\n",
    "from boax.optimization import acquisitions, maximizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4882-c610-4448-8699-545cecb97631",
   "metadata": {},
   "source": [
    "As our latent objective function we chose a sinusoid that we aim to maximize in the interval of [-3, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0aa909-2832-47e2-9427-01cd163b712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = jnp.array([[-3.0, 3.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5385417b-ebb4-4e75-89aa-0215d21e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "  return jnp.sin(4 * x[..., 0]) + jnp.cos(2 * x[..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00407e4b-1c72-4540-a08a-accd1216d277",
   "metadata": {},
   "source": [
    "To create the observation training data we sample random points from a uniform distribution, evaluate the objective functions at those points, and finish by adding gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6f727-86ed-4f31-aeda-ea380ee228fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_key, noise_key, maximizer_key = random.split(random.key(0), 3)\n",
    "x_train = random.uniform(sample_key, minval=bounds[:, 0], maxval=bounds[:, 1], shape=(10, 1))\n",
    "y_train = objective(x_train) + 0.3 * random.normal(noise_key, shape=(10,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846011-f012-4d34-8529-c74ede9a6adf",
   "metadata": {},
   "source": [
    "## Fitting a Gaussian Process model to the data\n",
    "\n",
    "With the observations in place, we can now focus on constructing a Gaussian Process model and fit it to the data. For this example we choose a simple setup of a constant zero mean function and a scaled RBF kernel. Note that we use the softplus function to constrain some of the models' hyperparameters to be strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ecbe1b4-adcb-424c-ba73-e92467348cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior(amplitude, length_scale, noise):\n",
    "    return models.predictive(\n",
    "        models.gaussian_process(\n",
    "            means.zero(),\n",
    "            kernels.scaled(kernels.rbf(nn.softplus(length_scale)), nn.softplus(amplitude)),\n",
    "        ),\n",
    "        likelihoods.gaussian(\n",
    "            nn.softplus(noise),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d664e642-509b-4000-bb46-85605f477133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_log_prob(params):\n",
    "    mvn = prior(**params)(x_train)\n",
    "    return -distributions.multivariate_normal.logpdf(mvn, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecb90-c62a-4d25-97eb-fb601691843f",
   "metadata": {},
   "source": [
    "Next we initialise the models' hyperparameters, the optimizer, and fit the model to the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d076f8a7-24cf-4155-80d9-21b796531544",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'amplitude': jnp.zeros(()),\n",
    "  'length_scale': jnp.zeros(()),\n",
    "  'noise': jnp.array(-5.),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ee0023-19ed-4c4b-b35f-49e3b8c3647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89522430-b013-483c-a28d-8b3a5a111e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, iteration):\n",
    "    loss, grads = value_and_grad(target_log_prob)(state[0])\n",
    "    updates, opt_state = optimizer.update(grads, state[1])\n",
    "    params = optax.apply_updates(state[0], updates)\n",
    "\n",
    "    return (params, opt_state), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b8b89cb-1769-4d35-9583-7515325b0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(next_params, next_opt_state), history = lax.scan(\n",
    "    jit(train_step),\n",
    "    (params, optimizer.init(params)),\n",
    "    jnp.arange(500)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b794d322-0a84-4370-8382-82239793fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(amplitude, length_scale, noise):\n",
    "    return models.predictive(\n",
    "        models.gaussian_process_regression(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            means.zero(),\n",
    "            kernels.scaled(kernels.rbf(nn.softplus(length_scale)), nn.softplus(amplitude)),\n",
    "        ),\n",
    "        likelihoods.gaussian(\n",
    "            nn.softplus(noise),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c468936c-6aea-41c6-a794-e7a885da0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = posterior(**next_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cde3708-158e-42cb-a249-d9eec22fb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acqf = acquisitions.upper_confidence_bound(surrogate, beta=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40bca6f9-990e-4341-a858-69ad2fd5b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximizer = maximizers.bfgs(acqf, bounds, q=1, num_restarts=5, num_raw_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4fb7322-0388-4a64-a650-e0482edcb86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates, values = maximizer(maximizer_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
