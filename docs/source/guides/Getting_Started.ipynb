{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14b8e7c-79f8-491c-ad6e-7a57c1103425",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this notebook we use boax to demonstrate a single step of a typical bayesion optimization process.\n",
    "\n",
    "We will begin by defining the latent objective function we want to maximize and its bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c736af-ef31-4b7c-bfc1-0483e70ca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "# Double precision is highly recommended.\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "from jax import lax\n",
    "from jax import nn\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax import value_and_grad\n",
    "\n",
    "import optax\n",
    "\n",
    "from boax.core import distributions, samplers\n",
    "from boax.prediction import kernels, likelihoods, means, models\n",
    "from boax.optimization import acquisitions, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4882-c610-4448-8699-545cecb97631",
   "metadata": {},
   "source": [
    "As our latent objective function we chose a sinusoid that we aim to maximize in the interval of [-3, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0aa909-2832-47e2-9427-01cd163b712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = jnp.array([[0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5385417b-ebb4-4e75-89aa-0215d21e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "  return 1 - jnp.linalg.norm(x - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00407e4b-1c72-4540-a08a-accd1216d277",
   "metadata": {},
   "source": [
    "To create the observation training data we sample random points from a uniform distribution, evaluate the objective functions at those points, and finish by adding gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce6f727-86ed-4f31-aeda-ea380ee228fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key, sampler_key, maximizer_key = random.split(random.key(0), 3)\n",
    "x_train = random.uniform(random.fold_in(data_key, 0), minval=bounds[:, 0], maxval=bounds[:, 1], shape=(10, 1))\n",
    "y_train = nn.standardize(objective(x_train) + 0.1 * random.normal(random.fold_in(data_key, 1), shape=(10,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846011-f012-4d34-8529-c74ede9a6adf",
   "metadata": {},
   "source": [
    "## Fitting a Gaussian Process model to the data\n",
    "\n",
    "With the observations in place, we can now focus on constructing a Gaussian Process model and fit it to the data. For this example we choose a simple setup of a constant zero mean function and a scaled RBF kernel. Note that we use the softplus function to constrain some of the models' hyperparameters to be strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d076f8a7-24cf-4155-80d9-21b796531544",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'amplitude': jnp.zeros(()),\n",
    "  'length_scale': jnp.zeros(()),\n",
    "  'noise': jnp.array(-5.),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38ee0023-19ed-4c4b-b35f-49e3b8c3647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optax.adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ecbe1b4-adcb-424c-ba73-e92467348cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    def model(amplitude, length_scale, noise):\n",
    "        return models.predictive(\n",
    "            models.gaussian_process(\n",
    "                means.zero(),\n",
    "                kernels.scaled(\n",
    "                    kernels.rbf(nn.softplus(length_scale)),\n",
    "                    nn.softplus(amplitude)\n",
    "                ),\n",
    "            ),\n",
    "            likelihoods.gaussian(nn.softplus(noise))\n",
    "        )\n",
    "    \n",
    "    def target_log_prob(params):\n",
    "        mvn = model(**params)(x_train)\n",
    "        return -jnp.sum(distributions.multivariate_normal.logpdf(mvn, y_train))\n",
    "\n",
    "    def train_step(state, iteration):\n",
    "        loss, grads = value_and_grad(target_log_prob)(state[0])\n",
    "        updates, opt_state = adam.update(grads, state[1])\n",
    "        params = optax.apply_updates(state[0], updates)\n",
    "        \n",
    "        return (params, opt_state), loss\n",
    "    \n",
    "    return lax.scan(\n",
    "        jit(train_step),\n",
    "        (params, adam.init(params)),\n",
    "        jnp.arange(500)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b8b89cb-1769-4d35-9583-7515325b0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "(next_params, next_opt_state), history = fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d237fd6-95bd-4185-a3af-a326e12d6192",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = models.predictive(\n",
    "    models.gaussian_process_regression(\n",
    "        means.zero(),\n",
    "        kernels.scaled(\n",
    "            kernels.rbf(nn.softplus(next_params['length_scale'])),\n",
    "            nn.softplus(next_params['amplitude'])\n",
    "        ),\n",
    "    )(\n",
    "        x_train,\n",
    "        y_train,\n",
    "    ),\n",
    "    likelihoods.gaussian(nn.softplus(next_params['noise']))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcaa27-41f9-4db7-9166-11e3d30bf23d",
   "metadata": {},
   "source": [
    "## Constructing and optimizing an acquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c24196f-c8af-42ae-b94c-7d6867aa5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = jnp.reshape(\n",
    "    samplers.halton_uniform(distributions.uniform.uniform(bounds[:, 0], bounds[:, 1]))(\n",
    "        sampler_key,\n",
    "        100,\n",
    "    ),\n",
    "    (100, 1, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "775ed88e-9949-4fd2-926f-df7011c92f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "acqf = optimizers.construct(\n",
    "    models.outcome_transformed(\n",
    "        surrogate,\n",
    "        distributions.multivariate_normal.as_normal\n",
    "    ),\n",
    "    acquisitions.upper_confidence_bound(2.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea6de0ff-f1de-4694-9b02-9ba07a9db6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfgs = optimizers.bfgs(acqf, bounds, x0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0425c2be-ef07-4cea-9a22-ef54b0ed2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = bfgs.init(maximizer_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4952451a-c52b-428c-b07e-7f23efc880de",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_candidates, values = bfgs.update(candidates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
