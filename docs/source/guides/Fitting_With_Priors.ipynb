{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14b8e7c-79f8-491c-ad6e-7a57c1103425",
   "metadata": {},
   "source": [
    "# Fitting with Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c736af-ef31-4b7c-bfc1-0483e70ca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import config\n",
    "\n",
    "# Double precision is highly recommended.\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from jax import jit\n",
    "from jax import lax\n",
    "from jax import nn\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jax import value_and_grad\n",
    "\n",
    "import optax\n",
    "\n",
    "from boax import prediction, optimization\n",
    "from boax.core import distributions, samplers\n",
    "from boax.prediction import kernels, likelihoods, means, models, objectives\n",
    "from boax.optimization import acquisitions, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3c4882-c610-4448-8699-545cecb97631",
   "metadata": {},
   "source": [
    "As our latent objective function we chose a sinusoid that we aim to maximize in the interval of [-3, 3]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0aa909-2832-47e2-9427-01cd163b712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = jnp.array([[0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385417b-ebb4-4e75-89aa-0215d21e968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    return 1 - jnp.linalg.norm(x - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00407e4b-1c72-4540-a08a-accd1216d277",
   "metadata": {},
   "source": [
    "To create the observation training data we sample random points from a uniform distribution, evaluate the objective functions at those points, and finish by adding gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce6f727-86ed-4f31-aeda-ea380ee228fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key, sampler_key, optimizer_key = random.split(random.key(0), 3)\n",
    "\n",
    "x_train = random.uniform(\n",
    "    random.fold_in(data_key, 0),\n",
    "    minval=bounds[:, 0],\n",
    "    maxval=bounds[:, 1],\n",
    "    shape=(10, 1)\n",
    ")\n",
    "\n",
    "y_train = objective(x_train) + 0.1 * random.normal(\n",
    "    random.fold_in(data_key, 1),\n",
    "    shape=(10,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846011-f012-4d34-8529-c74ede9a6adf",
   "metadata": {},
   "source": [
    "## Fitting a Gaussian Process model to the data\n",
    "\n",
    "With the observations in place, we can now focus on constructing a Gaussian Process model and fit it to the data. For this example we choose a simple setup of a constant zero mean function and a scaled RBF kernel. Note that we use the softplus function to constrain some of the models' hyperparameters to be strictly positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fe967-021d-4383-aed3-cde592e8e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'amplitude': jnp.zeros(()),\n",
    "    'length_scale': jnp.zeros(()),\n",
    "    'noise': jnp.zeros(()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee0023-19ed-4c4b-b35f-49e3b8c3647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optax.adam(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecbe1b4-adcb-424c-ba73-e92467348cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    def model(params):\n",
    "        return models.outcome_transformed(\n",
    "            models.gaussian_process(\n",
    "                means.zero(),\n",
    "                kernels.scaled(\n",
    "                    kernels.rbf(params['amplitude']),\n",
    "                    params['length_scale'],\n",
    "                ),\n",
    "            ),\n",
    "            likelihoods.gaussian(params['noise']),\n",
    "        )\n",
    "\n",
    "    def objective(params):\n",
    "        return objectives.penalized(\n",
    "            objectives.negative_log_likelihood(\n",
    "                distributions.multivariate_normal.logpdf\n",
    "            ),\n",
    "            jnp.sum(\n",
    "                distributions.gamma.logpdf(\n",
    "                    distributions.gamma.gamma(2.0, 0.15),\n",
    "                    params['amplitude'],\n",
    "                )\n",
    "            ),\n",
    "            jnp.sum(\n",
    "                distributions.gamma.logpdf(\n",
    "                    distributions.gamma.gamma(3.0, 6.0),\n",
    "                    params['length_scale'],\n",
    "                )\n",
    "            ),\n",
    "            jnp.sum(\n",
    "                distributions.gamma.logpdf(\n",
    "                    distributions.gamma.gamma(1.1, 0.05),\n",
    "                    params['noise'],\n",
    "                )\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def projection(params):\n",
    "        return {\n",
    "            'amplitude': nn.softplus(params['amplitude']),\n",
    "            'length_scale': nn.softplus(params['length_scale']),\n",
    "            'noise': nn.softplus(params['noise']) + 1e-4,\n",
    "        }\n",
    "\n",
    "    def step(state, iteration):\n",
    "        loss_fn = prediction.construct(model, objective, projection)\n",
    "        loss, grads = value_and_grad(loss_fn)(state[0], x_train, y_train)\n",
    "        updates, opt_state = adam.update(grads, state[1])\n",
    "        params = optax.apply_updates(state[0], updates)\n",
    "        \n",
    "        return (params, opt_state), loss\n",
    "    \n",
    "    (next_params, _), _ = lax.scan(\n",
    "        jit(step),\n",
    "        (params, adam.init(params)),\n",
    "        jnp.arange(500)\n",
    "    )\n",
    "\n",
    "    return projection(next_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdcaa27-41f9-4db7-9166-11e3d30bf23d",
   "metadata": {},
   "source": [
    "## Constructing and optimizing an acquisition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24196f-c8af-42ae-b94c-7d6867aa5527",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = jnp.reshape(\n",
    "    samplers.halton_uniform(\n",
    "        distributions.uniform.uniform(bounds[:, 0], bounds[:, 1])\n",
    "    )(\n",
    "        sampler_key,\n",
    "        100,\n",
    "    ),\n",
    "    (100, 1, -1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3f2faf-77a4-4dec-b109-0017e434235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x_train, y_train):\n",
    "    def model(params):\n",
    "        return models.outcome_transformed(\n",
    "            models.gaussian_process_regression(\n",
    "                means.zero(),\n",
    "                kernels.scaled(\n",
    "                    kernels.rbf(params['amplitude']),\n",
    "                    params['length_scale']\n",
    "                )\n",
    "            )(\n",
    "                x_train,\n",
    "                y_train,\n",
    "            ),\n",
    "            likelihoods.gaussian(params['noise']),\n",
    "            distributions.multivariate_normal.as_normal,\n",
    "        )\n",
    "\n",
    "    for i in range(10):\n",
    "        params = fit(x_train, nn.standardize(y_train))\n",
    "\n",
    "        acqf = optimization.construct(\n",
    "            model(params),\n",
    "            acquisitions.upper_confidence_bound(2.0),\n",
    "        )\n",
    "        \n",
    "        bfgs = optimizers.bfgs(acqf, bounds, x0, 10)\n",
    "        candidates = bfgs.init(random.fold_in(optimizer_key, i))\n",
    "        next_candidates, values = bfgs.update(candidates)\n",
    "\n",
    "        next_x = next_candidates[jnp.argmax(values)]\n",
    "        next_y = objective(next_x)\n",
    "        \n",
    "        x_train = jnp.vstack([x_train, next_x])\n",
    "        y_train = jnp.hstack([y_train, next_y])\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b64719-2c12-4c8a-a371-9392e4831fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_x_train, next_y_train = optimize(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
